{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed66880e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== F1: And(A,B) ===\n",
      "Formula: A & B\n",
      "Exact  : #SAT = 1  over 2^2 = 4\n",
      "Approx : #SAT ≈ 0.952  (CI 95%: [0.878, 1.026])\n",
      "samples N = 2050, successes k = 488, p_hat = 0.238049\n",
      "Relative error (point) = 4.78%\n",
      "\n",
      "=== F2: 7/8 clause ===\n",
      "Formula: ~A | ~B | ~C\n",
      "Exact  : #SAT = 7  over 2^3 = 8\n",
      "Approx : #SAT ≈ 7.013  (CI 95%: [6.899, 7.127])\n",
      "samples N = 2050, successes k = 1797, p_hat = 0.876585\n",
      "Relative error (point) = 0.18%\n",
      "\n",
      "=== F3: 5-var mixed ===\n",
      "Formula: (Implies(C, D)) & (B | C) & (Equivalent(A, ~E)) & (A | ~B) & (E | ~D)\n",
      "Exact  : #SAT = 2  over 2^5 = 32\n",
      "Approx : #SAT ≈ 2.248  (CI 95%: [1.894, 2.602])\n",
      "samples N = 2050, successes k = 144, p_hat = 0.070244\n",
      "Relative error (point) = 12.39%\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================\n",
    "# Exact vs Approximate Model Counting - Test Harness\n",
    "#  - include: utilities, exact brute force, Monte Carlo approx\n",
    "#  - run on a few small formulas where exact is feasible\n",
    "# ==============================================================\n",
    "\n",
    "import math, random\n",
    "from typing import Dict, Tuple\n",
    "from sympy import symbols\n",
    "from sympy.logic.boolalg import Boolean, And, Or, Not, Implies, Equivalent\n",
    "\n",
    "# ------------------ Utilities ------------------\n",
    "\n",
    "def vars_set(F: Boolean):\n",
    "    return list(sorted(F.free_symbols, key=lambda s: s.name))\n",
    "\n",
    "def eval_under(F: Boolean, assign: Dict):\n",
    "    return bool(F.subs(assign))\n",
    "\n",
    "def random_assignment(V, rng=random):\n",
    "    return {v: bool(rng.getrandbits(1)) for v in V}\n",
    "\n",
    "# ------------------ Exact (brute force) ------------------\n",
    "\n",
    "def exact_model_count(F: Boolean, limit_vars: int = 22) -> Tuple[int, int]:\n",
    "    V = vars_set(F)\n",
    "    n = len(V)\n",
    "    if n > limit_vars:\n",
    "        raise ValueError(f\"Exact count disabilitato per n={n} > {limit_vars}.\")\n",
    "    count = 0\n",
    "    for mask in range(1 << n):\n",
    "        assign = {V[i]: bool((mask >> i) & 1) for i in range(n)}\n",
    "        if eval_under(F, assign):\n",
    "            count += 1\n",
    "    return count, n\n",
    "\n",
    "# ------------------ Approximate (Monte Carlo) ------------------\n",
    "\n",
    "def required_samples_eps_delta(eps: float, delta: float) -> int:\n",
    "    if not (0 < eps < 1):   raise ValueError(\"eps deve essere in (0,1).\")\n",
    "    if not (0 < delta < 1): raise ValueError(\"delta deve essere in (0,1).\")\n",
    "    return math.ceil((1.0 / (2.0 * eps * eps)) * math.log(2.0 / delta))\n",
    "\n",
    "def inverse_normal_cdf(p: float) -> float:\n",
    "    # Acklam approximation\n",
    "    a = [ -3.969683028665376e+01,  2.209460984245205e+02,\n",
    "          -2.759285104469687e+02,  1.383577518672690e+02,\n",
    "          -3.066479806614716e+01,  2.506628277459239e+00 ]\n",
    "    b = [ -5.447609879822406e+01,  1.615858368580409e+02,\n",
    "          -1.556989798598866e+02,  6.680131188771972e+01,\n",
    "          -1.328068155288572e+01 ]\n",
    "    c = [ -7.784894002430293e-03, -3.223964580411365e-01,\n",
    "          -2.400758277161838e+00, -2.549732539343734e+00,\n",
    "           4.374664141464968e+00,  2.938163982698783e+00 ]\n",
    "    d = [ 7.784695709041462e-03,  3.224671290700398e-01,\n",
    "          2.445134137142996e+00,  3.754408661907416e+00 ]\n",
    "    plow, phigh = 0.02425, 1 - 0.02425\n",
    "    if p < plow:\n",
    "        q = math.sqrt(-2*math.log(p))\n",
    "        x = (((((c[0]*q + c[1])*q + c[2])*q + c[3])*q + c[4])*q + c[5]) / \\\n",
    "            ((((d[0]*q + d[1])*q + d[2])*q + d[3])*q + 1)\n",
    "    elif p > phigh:\n",
    "        q = math.sqrt(-2*math.log(1 - p))\n",
    "        x = -(((((c[0]*q + c[1])*q + c[2])*q + c[3])*q + c[4])*q + c[5]) / \\\n",
    "              ((((d[0]*q + d[1])*q + d[2])*q + d[3])*q + 1)\n",
    "    else:\n",
    "        q = p - 0.5; r = q*q\n",
    "        x = (((((a[0]*r + a[1])*r + a[2])*r + a[3])*r + a[4])*r + a[5])*q / \\\n",
    "            (((((b[0]*r + b[1])*r + b[2])*r + b[3])*r + b[4])*r + 1)\n",
    "    e = 0.5 * (1 + math.erf(x / math.sqrt(2))) - p\n",
    "    u = e * math.sqrt(2*math.pi) * math.exp(x*x/2)\n",
    "    return x - u / (1 + x*u/2)\n",
    "\n",
    "def clopper_pearson_ci_simple(k: int, N: int, alpha: float) -> Tuple[float, float]:\n",
    "    if N == 0: return (0.0, 1.0)\n",
    "    p_hat = k / N\n",
    "    z = inverse_normal_cdf(1 - alpha/2)\n",
    "    se = math.sqrt(p_hat * (1 - p_hat) / N) if 0 < p_hat < 1 else math.sqrt(0.25 / N)\n",
    "    lo = max(0.0, p_hat - z * se)\n",
    "    hi = min(1.0, p_hat + z * se)\n",
    "    return (lo, hi)\n",
    "\n",
    "def approx_model_count(F: Boolean, eps: float = 0.05, delta: float = 0.05,\n",
    "                       max_samples: int = None, rng: random.Random = None) -> dict:\n",
    "    rng = rng or random.Random()\n",
    "    V = vars_set(F); n = len(V)\n",
    "    N = required_samples_eps_delta(eps, delta)\n",
    "    if max_samples is not None: N = min(N, max_samples)\n",
    "    k = 0\n",
    "    for _ in range(N):\n",
    "        A = random_assignment(V, rng)\n",
    "        if eval_under(F, A): k += 1\n",
    "    p_hat = k / N\n",
    "    lo_p, hi_p = clopper_pearson_ci_simple(k, N, alpha=delta)\n",
    "    factor = 2**n\n",
    "    return {\n",
    "        \"n\": n, \"N\": N, \"k\": k,\n",
    "        \"p_hat\": p_hat, \"p_ci\": (lo_p, hi_p),\n",
    "        \"count_hat\": p_hat * factor,\n",
    "        \"count_ci\": (lo_p * factor, hi_p * factor),\n",
    "        \"eps\": eps, \"delta\": delta,\n",
    "    }\n",
    "\n",
    "# ------------------ Test Runner ------------------\n",
    "\n",
    "def compare_exact_vs_approx(name: str, F: Boolean,\n",
    "                            eps=0.05, delta=0.05, seed=42, max_samples=None):\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(f\"Formula: {F}\")\n",
    "    exact, n = exact_model_count(F)\n",
    "    print(f\"Exact  : #SAT = {exact}  over 2^{n} = {2**n}\")\n",
    "\n",
    "    res = approx_model_count(F, eps=eps, delta=delta,\n",
    "                             max_samples=max_samples, rng=random.Random(seed))\n",
    "    est = res[\"count_hat\"]; lo, hi = res[\"count_ci\"]\n",
    "    rel_err = abs(est - exact) / max(1, exact)\n",
    "    print(f\"Approx : #SAT ≈ {est:.3f}  (CI {int((1-delta)*100)}%: [{lo:.3f}, {hi:.3f}])\")\n",
    "    print(f\"samples N = {res['N']}, successes k = {res['k']}, p_hat = {res['p_hat']:.6f}\")\n",
    "    print(f\"Relative error (point) = {100*rel_err:.2f}%\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Vars\n",
    "    A, B, C, D, E = symbols('A B C D E')\n",
    "\n",
    "    # 1) Facile: AND su 2 variabili -> 1 modello su 4\n",
    "    F1 = And(A, B)  # #SAT = 1, n=2\n",
    "    # 2) Classico \"7 su 8\": falso solo per A=B=C=True\n",
    "    F2 = Or(Not(A), Not(B), Not(C))  # #SAT = 7, n=3\n",
    "    # 3) Formula a 5 variabili, non banale\n",
    "    F3 = And(\n",
    "        Or(A, Not(B)),\n",
    "        Or(B, C),\n",
    "        Implies(C, D),\n",
    "        Or(Not(D), E),\n",
    "        Equivalent(A, Not(E))\n",
    "    )\n",
    "\n",
    "    # Confronti (eps=5%, delta=5%). Puoi ridurre eps per più precisione (aumenta N)\n",
    "    compare_exact_vs_approx(\"F1: And(A,B)\", F1, eps=0.03, delta=0.05, seed=7)\n",
    "    compare_exact_vs_approx(\"F2: 7/8 clause\", F2, eps=0.03, delta=0.05, seed=7)\n",
    "    compare_exact_vs_approx(\"F3: 5-var mixed\", F3, eps=0.03, delta=0.05, seed=7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
